{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investment Returns Analysis with Polars\n",
    "\n",
    "This notebook demonstrates using Polars for investment portfolio analysis, including:\n",
    "- Common Polars DataFrame operations\n",
    "- Efficient data transformations\n",
    "- Performance comparisons with a VOO benchmark\n",
    "- XIRR calculations for money-weighted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars version: 1.32.3\n",
      "Nasdaq Data Link configured: Yes\n",
      "All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For XIRR calculations\n",
    "import numpy_financial as npf\n",
    "\n",
    "# For data fetching using Nasdaq Data Link\n",
    "import os\n",
    "import nasdaqdatalink\n",
    "from typing import Dict, List, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# For visualization (still need matplotlib for plots)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Configure Polars display options\n",
    "pl.Config.set_tbl_rows(10)\n",
    "pl.Config.set_fmt_str_lengths(50)\n",
    "\n",
    "# Configure Nasdaq Data Link\n",
    "api_key = os.getenv('NASDAQ_DATA_LINK_API_KEY')\n",
    "if api_key:\n",
    "    nasdaqdatalink.ApiConfig.api_key = api_key\n",
    "    # Enable retries for robustness\n",
    "    nasdaqdatalink.ApiConfig.use_retries = True\n",
    "    nasdaqdatalink.ApiConfig.number_of_retries = 3\n",
    "    nasdaqdatalink.ApiConfig.retry_status_codes = [429, 500, 501, 502, 503, 504]\n",
    "\n",
    "print(f\"Polars version: {pl.__version__}\")\n",
    "print(f\"Nasdaq Data Link configured: {'Yes' if api_key else 'No - set NASDAQ_DATA_LINK_API_KEY in .env file'}\")\n",
    "print(\"All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2018.csv: 42 transactions\n",
      "Loaded 2019.csv: 42 transactions\n",
      "Loaded 2020.csv: 195 transactions\n",
      "Loaded 2021.csv: 218 transactions\n",
      "Loaded 2022.csv: 289 transactions\n",
      "Loaded 2023.csv: 257 transactions\n",
      "Loaded 2024.csv: 382 transactions\n",
      "Loaded 2025.csv: 251 transactions\n",
      "\n",
      "Total transactions loaded: 1676\n"
     ]
    }
   ],
   "source": [
    "def load_transactions():\n",
    "    \"\"\"Load all transaction CSV files and combine them using Polars\"\"\"\n",
    "    transactions_dir = Path('/Users/bhargav/Git/investments/transactions')\n",
    "    all_transactions = []\n",
    "    \n",
    "    # Define schema to ensure correct data types\n",
    "    schema_overrides = {\n",
    "        \"Price USD\": pl.Float64,\n",
    "        \"Quantity\": pl.Float64,\n",
    "        \"Amount USD\": pl.Float64\n",
    "    }\n",
    "    \n",
    "    for csv_file in sorted(transactions_dir.glob('*.csv')):\n",
    "        # Read CSV with Polars, specifying schema overrides\n",
    "        df = pl.read_csv(csv_file, schema_overrides=schema_overrides)\n",
    "        # Clean column names (remove BOM if present)\n",
    "        df = df.rename({col: col.replace('﻿', '') for col in df.columns})\n",
    "        all_transactions.append(df)\n",
    "        print(f\"Loaded {csv_file.name}: {len(df)} transactions\")\n",
    "    \n",
    "    # Combine all years using Polars concat\n",
    "    transactions = pl.concat(all_transactions, how=\"vertical\")\n",
    "    \n",
    "    # Convert date column and sort (fixed date format)\n",
    "    transactions = (\n",
    "        transactions\n",
    "        .with_columns(\n",
    "            pl.col(\"Trade Date\").str.to_date(format=\"%m/%d/%Y\")  # Fixed date format\n",
    "        )\n",
    "        .sort(\"Trade Date\")\n",
    "    )\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "# Load the data\n",
    "transactions = load_transactions()\n",
    "print(f\"\\nTotal transactions loaded: {len(transactions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────────┬──────────┬────────┬───────────────┬───────────┬──────────┬────────────┐\n",
      "│ Trade Date ┆ Type     ┆ Ticker ┆ Security Type ┆ Price USD ┆ Quantity ┆ Amount USD │\n",
      "│ ---        ┆ ---      ┆ ---    ┆ ---           ┆ ---       ┆ ---      ┆ ---        │\n",
      "│ date       ┆ str      ┆ str    ┆ str           ┆ f64       ┆ f64      ┆ f64        │\n",
      "╞════════════╪══════════╪════════╪═══════════════╪═══════════╪══════════╪════════════╡\n",
      "│ 2018-07-19 ┆ BUY      ┆ SCHF   ┆ ETF           ┆ 33.25     ┆ 74.0     ┆ -2460.5    │\n",
      "│ 2018-07-19 ┆ BUY      ┆ SCHX   ┆ ETF           ┆ 67.0      ┆ 74.0     ┆ -4958.0    │\n",
      "│ 2018-07-24 ┆ BUY      ┆ SCHA   ┆ ETF           ┆ 75.0      ┆ 25.0     ┆ -1875.0    │\n",
      "│ 2018-09-12 ┆ BUY      ┆ FTEC   ┆ ETF           ┆ 59.42     ┆ 40.0     ┆ -2376.8    │\n",
      "│ 2018-09-27 ┆ REINVEST ┆ FTEC   ┆ ETF           ┆ 60.19     ┆ 0.0937   ┆ -5.64      │\n",
      "└────────────┴──────────┴────────┴───────────────┴───────────┴──────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "def consolidate_transaction_types(df):\n",
    "    \"\"\"\n",
    "    Consolidate duplicate and similar transaction types using Polars\n",
    "    \"\"\"\n",
    "    # Create mapping for consolidation\n",
    "    type_mapping = {\n",
    "        # Deposits - consolidate variations\n",
    "        'DEPOSIT': 'Deposit',\n",
    "        'Deposit': 'Deposit',\n",
    "        \n",
    "        # Splits - consolidate variations\n",
    "        'STK SPLT': 'Split',\n",
    "        'SPLT': 'Split',\n",
    "        'Split': 'Split',\n",
    "        \n",
    "        # Dividends - keep as is\n",
    "        'Dividend': 'Dividend',\n",
    "        'DBS': 'Dividend',\n",
    "        'DBT': 'Dividend',\n",
    "        \n",
    "        # Reinvestments\n",
    "        'Reinvest': 'Reinvest',\n",
    "        \n",
    "        # Buys and Sells\n",
    "        'Buy': 'Buy',\n",
    "        'Sell': 'Sell',\n",
    "        'LIQ': 'Sell',      # Liquidation\n",
    "        \n",
    "        # Interest\n",
    "        'Interest': 'Interest',\n",
    "        \n",
    "        # Distributions and capital gains\n",
    "        'Distribution': 'Distribution',\n",
    "        'CAP': 'Capital Gain',\n",
    "        \n",
    "        # Tax-related\n",
    "        'WHT': 'Tax Withheld',     # Withholding tax\n",
    "        'FWT': 'Tax Withheld',     # Foreign withholding tax\n",
    "        \n",
    "        # Fees\n",
    "        'ADR': 'Fee',          # ADR fee\n",
    "        'MER': 'Fee',    # Management expense ratio\n",
    "        \n",
    "        # Corporate actions\n",
    "        'WDL': 'Withdrawal',       # Withdrawal\n",
    "        'BNK': 'Bank Transfer',    # Bank transfer\n",
    "        'CIL': 'Corporate Action',     # Cash in lieu\n",
    "        'Exchange': 'Corporate Action',     # Currency exchange or security exchange\n",
    "    }\n",
    "    \n",
    "    # Apply the mapping using Polars replace and then uppercase\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"Type\")\n",
    "        .replace(type_mapping, default=pl.col(\"Type\"))\n",
    "        .str.strip_chars()\n",
    "        .str.to_uppercase()\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "transactions = consolidate_transaction_types(transactions)\n",
    "print(transactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction consolidated:\n",
      "shape: (14, 2)\n",
      "┌──────────────────┬───────┐\n",
      "│ Type             ┆ count │\n",
      "│ ---              ┆ ---   │\n",
      "│ str              ┆ u32   │\n",
      "╞══════════════════╪═══════╡\n",
      "│ DIVIDEND         ┆ 619   │\n",
      "│ REINVEST         ┆ 415   │\n",
      "│ BUY              ┆ 398   │\n",
      "│ WITHDRAWAL       ┆ 68    │\n",
      "│ INTEREST         ┆ 57    │\n",
      "│ …                ┆ …     │\n",
      "│ BANK TRANSFER    ┆ 13    │\n",
      "│ SPLIT            ┆ 10    │\n",
      "│ CAPITAL GAIN     ┆ 10    │\n",
      "│ CORPORATE ACTION ┆ 4     │\n",
      "│ DISTRIBUTION     ┆ 1     │\n",
      "└──────────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"Transaction consolidated:\")\n",
    "print(\n",
    "    transactions\n",
    "    .group_by(\"Type\")\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVANCED POLARS OPERATIONS\n",
      "============================================================\n",
      "\n",
      "1. DATE OPERATIONS - Extract date components:\n",
      "shape: (10, 5)\n",
      "┌────────────┬──────┬───────┬─────────┬─────────┐\n",
      "│ Trade Date ┆ year ┆ month ┆ quarter ┆ weekday │\n",
      "│ ---        ┆ ---  ┆ ---   ┆ ---     ┆ ---     │\n",
      "│ date       ┆ i32  ┆ i8    ┆ i8      ┆ i8      │\n",
      "╞════════════╪══════╪═══════╪═════════╪═════════╡\n",
      "│ 2018-07-19 ┆ 2018 ┆ 7     ┆ 3       ┆ 4       │\n",
      "│ 2018-07-19 ┆ 2018 ┆ 7     ┆ 3       ┆ 4       │\n",
      "│ 2018-07-24 ┆ 2018 ┆ 7     ┆ 3       ┆ 2       │\n",
      "│ 2018-09-12 ┆ 2018 ┆ 9     ┆ 3       ┆ 3       │\n",
      "│ 2018-09-27 ┆ 2018 ┆ 9     ┆ 3       ┆ 4       │\n",
      "│ 2018-10-01 ┆ 2018 ┆ 10    ┆ 4       ┆ 1       │\n",
      "│ 2018-10-01 ┆ 2018 ┆ 10    ┆ 4       ┆ 1       │\n",
      "│ 2018-10-02 ┆ 2018 ┆ 10    ┆ 4       ┆ 2       │\n",
      "│ 2018-10-08 ┆ 2018 ┆ 10    ┆ 4       ┆ 1       │\n",
      "│ 2018-10-09 ┆ 2018 ┆ 10    ┆ 4       ┆ 2       │\n",
      "└────────────┴──────┴───────┴─────────┴─────────┘\n",
      "\n",
      "2. PIVOT TABLE - Transactions by year and type:\n",
      "shape: (8, 15)\n",
      "┌──────┬────────────┬───────────┬──────────┬───┬─────────────┬─────────┬─────────────┬─────────────┐\n",
      "│ Year ┆ BUY        ┆ REINVEST  ┆ INTEREST ┆ … ┆ CORPORATE   ┆ FEE     ┆ DISTRIBUTIO ┆ BANK        │\n",
      "│ ---  ┆ ---        ┆ ---       ┆ ---      ┆   ┆ ACTION      ┆ ---     ┆ N           ┆ TRANSFER    │\n",
      "│ i32  ┆ f64        ┆ f64       ┆ f64      ┆   ┆ ---         ┆ f64     ┆ ---         ┆ ---         │\n",
      "│      ┆            ┆           ┆          ┆   ┆ f64         ┆         ┆ f64         ┆ f64         │\n",
      "╞══════╪════════════╪═══════════╪══════════╪═══╪═════════════╪═════════╪═════════════╪═════════════╡\n",
      "│ 2018 ┆ -56815.32  ┆ -4543.34  ┆ 0.0      ┆ … ┆ 0.0         ┆ 0.0     ┆ 0.0         ┆ 0.0         │\n",
      "│ 2019 ┆ -18378.84  ┆ -869.56   ┆ 1.8      ┆ … ┆ 0.0         ┆ 0.0     ┆ 0.0         ┆ 0.0         │\n",
      "│ 2020 ┆ -271240.53 ┆ -3410.02  ┆ 1.4      ┆ … ┆ 0.0         ┆ 0.0     ┆ 0.0         ┆ 0.0         │\n",
      "│ 2021 ┆ -153794.44 ┆ -2617.33  ┆ 0.19     ┆ … ┆ 0.0         ┆ 0.0     ┆ 0.0         ┆ 0.0         │\n",
      "│ 2022 ┆ -133312.49 ┆ -2657.05  ┆ 3.65     ┆ … ┆ 28.14       ┆ -5.0    ┆ -2.0        ┆ 0.0         │\n",
      "│ 2023 ┆ -821000.0  ┆ -16508.1  ┆ 0.87     ┆ … ┆ 0.0         ┆ 4825.23 ┆ 0.0         ┆ 0.0         │\n",
      "│ 2024 ┆ -303561.23 ┆ -24102.18 ┆ 3.94     ┆ … ┆ 0.0         ┆ -17.69  ┆ 0.0         ┆ -185000.0   │\n",
      "│ 2025 ┆ -405605.35 ┆ -2482.4   ┆ 2.63     ┆ … ┆ 0.0         ┆ -0.11   ┆ 0.0         ┆ 480000.0    │\n",
      "└──────┴────────────┴───────────┴──────────┴───┴─────────────┴─────────┴─────────────┴─────────────┘\n",
      "\n",
      "3. CONDITIONAL LOGIC - Categorize transaction sizes:\n",
      "shape: (6, 3)\n",
      "┌──────────────────────┬───────┬───────────────┐\n",
      "│ transaction_category ┆ count ┆ avg_amount    │\n",
      "│ ---                  ┆ ---   ┆ ---           │\n",
      "│ str                  ┆ u32   ┆ f64           │\n",
      "╞══════════════════════╪═══════╪═══════════════╡\n",
      "│ Large Purchase       ┆ 54    ┆ -66758.840556 │\n",
      "│ Zero                 ┆ 12    ┆ 0.0           │\n",
      "│ Small Purchase       ┆ 636   ┆ -60.533726    │\n",
      "│ Medium Purchase      ┆ 246   ┆ -4033.395122  │\n",
      "│ Small Income         ┆ 599   ┆ 52.779165     │\n",
      "│ Large Income         ┆ 129   ┆ 33488.287829  │\n",
      "└──────────────────────┴───────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# More advanced Polars operations\n",
    "print(\"ADVANCED POLARS OPERATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Date operations\n",
    "print(\"\\n1. DATE OPERATIONS - Extract date components:\")\n",
    "date_analysis = (\n",
    "    transactions\n",
    "    .with_columns([\n",
    "        pl.col(\"Trade Date\").dt.year().alias(\"year\"),\n",
    "        pl.col(\"Trade Date\").dt.month().alias(\"month\"),\n",
    "        pl.col(\"Trade Date\").dt.quarter().alias(\"quarter\"),\n",
    "        pl.col(\"Trade Date\").dt.weekday().alias(\"weekday\")\n",
    "    ])\n",
    "    .select([\"Trade Date\", \"year\", \"month\", \"quarter\", \"weekday\"])\n",
    "    .head(10)\n",
    ")\n",
    "print(date_analysis)\n",
    "\n",
    "# 2. Pivot table\n",
    "print(\"\\n2. PIVOT TABLE - Transactions by year and type:\")\n",
    "pivot_result = (\n",
    "    transactions\n",
    "    .with_columns(\n",
    "        pl.col(\"Trade Date\").dt.year().alias(\"Year\")\n",
    "    )\n",
    "    .pivot(\n",
    "        values=\"Amount USD\",\n",
    "        index=\"Year\", \n",
    "        columns=\"Type\",\n",
    "        aggregate_function=\"sum\"\n",
    "    )\n",
    "    .fill_null(0)\n",
    ")\n",
    "print(pivot_result)\n",
    "\n",
    "# 3. Conditional operations with when/then/otherwise\n",
    "print(\"\\n3. CONDITIONAL LOGIC - Categorize transaction sizes:\")\n",
    "categorized = (\n",
    "    transactions\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"Amount USD\") < -10000)\n",
    "        .then(pl.lit(\"Large Purchase\"))\n",
    "        .when(pl.col(\"Amount USD\") < -1000)\n",
    "        .then(pl.lit(\"Medium Purchase\"))\n",
    "        .when(pl.col(\"Amount USD\") < 0)\n",
    "        .then(pl.lit(\"Small Purchase\"))\n",
    "        .when(pl.col(\"Amount USD\") > 1000)\n",
    "        .then(pl.lit(\"Large Income\"))\n",
    "        .when(pl.col(\"Amount USD\") > 0)\n",
    "        .then(pl.lit(\"Small Income\"))\n",
    "        .otherwise(pl.lit(\"Zero\"))\n",
    "        .alias(\"transaction_category\")\n",
    "    )\n",
    "    .group_by(\"transaction_category\")\n",
    "    .agg([\n",
    "        pl.count().alias(\"count\"),\n",
    "        pl.col(\"Amount USD\").mean().alias(\"avg_amount\")\n",
    "    ])\n",
    ")\n",
    "print(categorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 1284 equity transactions\n",
      "\n",
      "Unique tickers (83):\n",
      "[' NOV 24 PUT 517.50', 'AAPL', 'ABNB', 'ADSK', 'ADYEY', 'AMD', 'AMZN', 'ANET', 'APPN', 'ASML', 'ATVI', 'AVB', 'BABA', 'BRKB', 'BTCO', 'CFLT', 'CHGG', 'CRM', 'CRWD', 'DIS', 'DXCM', 'ETSY', 'FB', 'FBSOX', 'FCOM', 'FHLC', 'FSLY', 'FTEC', 'FTNT', 'FUBO', 'FVRR', 'GS', 'HUBS', 'IDXX', 'IYW', 'JATAX', 'JD', 'LKNCY', 'LMND', 'MA', 'MELI', 'META', 'MKC', 'MSFT', 'MTN', 'NET', 'NFLX', 'NICE', 'NTDOY', 'NVDA', 'OKTA', 'PAYC', 'PINS', 'POTX', 'PYPL', 'QQQ', 'ROKU', 'SCHA', 'SCHF', 'SCHX', 'SCHZ', 'SHOP', 'SNBR', 'SNPS', 'TDOC', 'TEAM', 'TSLA', 'TTD', 'TWLO', 'TXG', 'UAL', 'UBER', 'UPST', 'VDC', 'VGT', 'VMSXX', 'VOO', 'VOX', 'VTI', 'WEX', 'ZBRA', 'ZM', 'ZNGA']\n"
     ]
    }
   ],
   "source": [
    "def filter_equity_transactions(df, MONEY_MARKET_FUNDS = ['VMFXX', 'QACDS', 'SPAXX', 'FDRXX', 'SWVXX', 'VMMXX']):\n",
    "    \"\"\"Filter for equity/ETF transactions only using Polars\"\"\"\n",
    "    # Chain operations for efficient filtering\n",
    "    df_filtered = (\n",
    "        df\n",
    "        # Remove money market funds\n",
    "        .filter(~pl.col(\"Ticker\").is_in(MONEY_MARKET_FUNDS))\n",
    "        # Keep only relevant transaction types\n",
    "        .filter(pl.col(\"Type\").is_in(['BUY', 'SELL', 'DIVIDEND', 'REINVEST', 'CAPITAL GAIN']))\n",
    "        # Remove rows without tickers\n",
    "        .filter(pl.col(\"Ticker\").is_not_null())\n",
    "    )\n",
    "    \n",
    "    return df_filtered\n",
    "equity_transactions = filter_equity_transactions(transactions)\n",
    "print(f\"Filtered to {len(equity_transactions)} equity transactions\")\n",
    "\n",
    "print(f\"\\nUnique tickers ({equity_transactions['Ticker'].n_unique()}):\")\n",
    "unique_tickers = (\n",
    "    equity_transactions\n",
    "    .select(\"Ticker\")\n",
    "    .unique()\n",
    "    .sort(\"Ticker\")\n",
    "    .get_column(\"Ticker\")\n",
    "    .to_list()\n",
    ")\n",
    "print(sorted(unique_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nasdaq Data Fetcher initialized with official library\n",
      "API Key status: Set\n",
      "\n",
      "Built-in robustness features:\n",
      "  - Automatic retries: 3 attempts\n",
      "  - Handles rate limiting (429 errors)\n",
      "  - Handles server errors (500-504)\n",
      "  - Automatic pagination for large datasets\n",
      "  - Caching to minimize API calls\n"
     ]
    }
   ],
   "source": [
    "class NasdaqDataFetcher:\n",
    "    \"\"\"Fetch historical data from Nasdaq Data Link using the official library - returns Polars DataFrames\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=None):\n",
    "        self.api_key = api_key or os.getenv('NASDAQ_DATA_LINK_API_KEY')\n",
    "        if self.api_key:\n",
    "            nasdaqdatalink.ApiConfig.api_key = self.api_key\n",
    "            # Configure robustness features\n",
    "            nasdaqdatalink.ApiConfig.use_retries = True\n",
    "            nasdaqdatalink.ApiConfig.number_of_retries = 3\n",
    "            nasdaqdatalink.ApiConfig.retry_status_codes = [429, 500, 501, 502, 503, 504]\n",
    "        else:\n",
    "            print(\"WARNING: No API key found. Set NASDAQ_DATA_LINK_API_KEY in .env file\")\n",
    "            print(\"You can get a free API key at: https://data.nasdaq.com/sign-up\")\n",
    "        self.cache = {}\n",
    "    \n",
    "    def get_price_history(self, ticker: str, start_date: str, end_date: str) -> pl.DataFrame:\n",
    "        \"\"\"Get daily price history for a ticker including adjusted close and dividends using SHARADAR/SEP\"\"\"\n",
    "        # Check cache first\n",
    "        cache_key = f\"{ticker}_{start_date}_{end_date}\"\n",
    "        if cache_key in self.cache:\n",
    "            return self.cache[cache_key]\n",
    "        \n",
    "        if not self.api_key:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Use the nasdaq-data-link library to fetch from SHARADAR/SEP table\n",
    "            # This provides adjusted close prices and dividend information\n",
    "            data = nasdaqdatalink.get_table(\n",
    "                'SHARADAR/SEP',\n",
    "                ticker=ticker,\n",
    "                date={'gte': start_date, 'lte': end_date},\n",
    "                qopts={'columns': ['ticker', 'date', 'closeadj', 'divamt']},\n",
    "                paginate=True  # Automatically handle pagination for large datasets\n",
    "            )\n",
    "            \n",
    "            if data is not None and not data.empty:\n",
    "                # Convert pandas DataFrame to Polars for consistency\n",
    "                df = pl.from_pandas(data)\n",
    "                \n",
    "                # Ensure date column is properly typed\n",
    "                if 'date' in df.columns:\n",
    "                    df = df.with_columns(\n",
    "                        pl.col('date').cast(pl.Date)\n",
    "                    ).sort('date')\n",
    "                \n",
    "                self.cache[cache_key] = df\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"No data found for {ticker} in the specified date range\")\n",
    "                return pl.DataFrame()\n",
    "                \n",
    "        except nasdaqdatalink.NotFoundError:\n",
    "            print(f\"Ticker {ticker} not found in SHARADAR/SEP database\")\n",
    "            return pl.DataFrame()\n",
    "            \n",
    "        except nasdaqdatalink.LimitExceededError:\n",
    "            print(f\"API limit exceeded. Please wait.\")\n",
    "            return pl.DataFrame()\n",
    "            \n",
    "        except nasdaqdatalink.AuthenticationError:\n",
    "            print(f\"Authentication failed. Please check your API key.\")\n",
    "            return pl.DataFrame()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "            return pl.DataFrame()\n",
    "    \n",
    "    def get_fund_prices(self, ticker: str, start_date: str, end_date: str) -> pl.DataFrame:\n",
    "        \"\"\"Get fund prices from SHARADAR/SFP for ETFs and mutual funds\"\"\"\n",
    "        \n",
    "        cache_key = f\"fund_{ticker}_{start_date}_{end_date}\"\n",
    "        if cache_key in self.cache:\n",
    "            return self.cache[cache_key]\n",
    "        \n",
    "        if not self.api_key:\n",
    "            return self.get_price_history(ticker, start_date, end_date)  # Use dummy data\n",
    "        \n",
    "        try:\n",
    "            # Try SHARADAR/SFP for funds (ETFs, mutual funds)\n",
    "            data = nasdaqdatalink.get_table(\n",
    "                'SHARADAR/SFP',\n",
    "                ticker=ticker,\n",
    "                date={'gte': start_date, 'lte': end_date},\n",
    "                qopts={'columns': ['ticker', 'date', 'closeadj', 'divamt']},\n",
    "                paginate=True\n",
    "            )\n",
    "            \n",
    "            if data is not None and not data.empty:\n",
    "                df = pl.from_pandas(data)\n",
    "                if 'date' in df.columns:\n",
    "                    df = df.with_columns(\n",
    "                        pl.col('date').cast(pl.Date)\n",
    "                    ).sort('date')\n",
    "                self.cache[cache_key] = df\n",
    "                return df\n",
    "            else:\n",
    "                return pl.DataFrame()\n",
    "                \n",
    "        except Exception:\n",
    "            # If not found in SFP, fallback to SEP\n",
    "            return self.get_price_history(ticker, start_date, end_date)\n",
    "    \n",
    "    def get_ticker_info(self, ticker: str) -> dict:\n",
    "        \"\"\"Get ticker metadata from SHARADAR/TICKERS table\"\"\"\n",
    "        \n",
    "        if not self.api_key:\n",
    "            return {}\n",
    "        \n",
    "        try:\n",
    "            data = nasdaqdatalink.get_table(\n",
    "                'SHARADAR/TICKERS',\n",
    "                ticker=ticker,\n",
    "                qopts={'columns': ['ticker', 'name', 'exchange', 'isdelisted', 'category', 'sector', 'industry']}\n",
    "            )\n",
    "            \n",
    "            if data is not None and not data.empty:\n",
    "                return data.iloc[0].to_dict()\n",
    "            return {}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching ticker info for {ticker}: {e}\")\n",
    "            return {}\n",
    "\n",
    "# Initialize the fetcher with built-in robustness\n",
    "fetcher = NasdaqDataFetcher()\n",
    "print(\"Nasdaq Data Fetcher initialized with official library\")\n",
    "print(\"API Key status:\", \"Set\" if fetcher.api_key else \"Not set (using dummy data)\")\n",
    "print(\"\\nBuilt-in robustness features:\")\n",
    "print(\"  - Automatic retries: 3 attempts\")\n",
    "print(\"  - Handles rate limiting (429 errors)\")\n",
    "print(\"  - Handles server errors (500-504)\")\n",
    "print(\"  - Automatic pagination for large datasets\")\n",
    "print(\"  - Caching to minimize API calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Filter Relevant Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "    \"\"\"Track portfolio holdings and calculate values over time using Polars\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.holdings = {}  # ticker -> shares\n",
    "        self.cash_flows = []  # List of (date, amount) for XIRR\n",
    "        self.history = []  # Daily portfolio values\n",
    "    \n",
    "    def process_transaction(self, date, txn_type, ticker, quantity, amount):\n",
    "        \"\"\"Process a single transaction\"\"\"\n",
    "        if ticker not in self.holdings:\n",
    "            self.holdings[ticker] = 0\n",
    "        \n",
    "        if txn_type in ['BUY']:\n",
    "            # Money leaves account (negative cash flow)\n",
    "            self.holdings[ticker] += abs(quantity)\n",
    "            self.cash_flows.append((date, -abs(amount)))\n",
    "            \n",
    "        elif txn_type in ['REINVEST']:\n",
    "            # Dividend reinvested - no net cash flow for XIRR\n",
    "            # But we do increase share count\n",
    "            self.holdings[ticker] += abs(quantity)\n",
    "            \n",
    "        elif txn_type == 'SELL':\n",
    "            # Money enters account (positive cash flow)\n",
    "            self.holdings[ticker] -= abs(quantity)\n",
    "            self.cash_flows.append((date, abs(amount)))\n",
    "            \n",
    "        elif txn_type == 'DIVIDEND' and quantity == 0:\n",
    "            # Cash dividend (not reinvested)\n",
    "            self.cash_flows.append((date, abs(amount)))\n",
    "            \n",
    "        elif txn_type == 'CAPITAL GAIN':\n",
    "            # Capital gains distribution (usually mutual funds)\n",
    "            # If reinvested, no cash flow\n",
    "            if quantity != 0:\n",
    "                self.holdings[ticker] += abs(quantity)\n",
    "    \n",
    "    def calculate_value(self, date, price_data):\n",
    "        \"\"\"Calculate total portfolio value on a given date using Polars DataFrames\"\"\"\n",
    "        total_value = 0\n",
    "        for ticker, shares in self.holdings.items():\n",
    "            if shares > 0 and ticker in price_data:\n",
    "                # Get most recent price up to this date\n",
    "                ticker_prices = price_data[ticker]\n",
    "                prices_before = ticker_prices.filter(pl.col('date') <= date)\n",
    "                if len(prices_before) > 0:\n",
    "                    # Get the last price using Polars\n",
    "                    price = prices_before['closeadj'][-1]\n",
    "                    total_value += shares * price\n",
    "        return total_value\n",
    "    \n",
    "    def calculate_xirr(self, end_date, end_value):\n",
    "        \"\"\"Calculate XIRR including final portfolio value\"\"\"\n",
    "        if len(self.cash_flows) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Add final portfolio value as positive cash flow\n",
    "        all_flows = self.cash_flows + [(end_date, end_value)]\n",
    "        \n",
    "        # Separate dates and amounts for numpy_financial\n",
    "        dates = [cf[0] for cf in all_flows]\n",
    "        amounts = [cf[1] for cf in all_flows]\n",
    "        \n",
    "        # Convert dates to datetime if they're not already\n",
    "        dates_dt = []\n",
    "        for d in dates:\n",
    "            if isinstance(d, datetime):\n",
    "                dates_dt.append(d)\n",
    "            else:\n",
    "                dates_dt.append(datetime.combine(d, datetime.min.time()))\n",
    "        \n",
    "        try:\n",
    "            xirr = npf.xirr(amounts, dates_dt)\n",
    "            return xirr * 100 if xirr is not None else None  # Convert to percentage\n",
    "        except:\n",
    "            # XIRR calculation can fail if returns are extreme\n",
    "            return None\n",
    "\n",
    "print(\"Portfolio tracking class defined with Polars support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Nasdaq Data Link Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get date range and tickers using Polars operations\n",
    "date_stats = equity_transactions.select([\n",
    "    pl.col('Trade Date').min().alias('start_date'),\n",
    "    pl.col('Trade Date').max().alias('end_date')\n",
    "]).row(0)\n",
    "\n",
    "start_date = date_stats[0].strftime('%Y-%m-%d')\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "tickers = equity_transactions['Ticker'].unique().to_list()\n",
    "\n",
    "print(f\"Fetching data for {len(tickers)} tickers\")\n",
    "print(f\"Date range: {start_date} to {end_date}\")\n",
    "\n",
    "# Fetch price data\n",
    "price_data = {}\n",
    "failed_tickers = []\n",
    "\n",
    "# Common ETF list for trying SFP table first\n",
    "COMMON_ETFS = ['VOO', 'VTI', 'QQQ', 'SCHX', 'SCHF', 'SCHA', 'SCHZ', 'VGT', 'VDC', 'VOX', \n",
    "               'FTEC', 'FHLC', 'FCOM', 'IYW', 'FBSOX', 'BTCO', 'POTX']\n",
    "\n",
    "# Always fetch VOO for benchmark\n",
    "print(\"\\nFetching VOO benchmark data...\")\n",
    "voo_prices = fetcher.get_fund_prices('VOO', start_date, end_date)\n",
    "if voo_prices.is_empty():\n",
    "    # Try SEP if SFP fails\n",
    "    voo_prices = fetcher.get_price_history('VOO', start_date, end_date)\n",
    "if not voo_prices.is_empty():\n",
    "    price_data['VOO'] = voo_prices\n",
    "    print(f\"  ✓ VOO: {len(voo_prices)} days of data\")\n",
    "else:\n",
    "    print(f\"  ✗ VOO: No data available\")\n",
    "\n",
    "# Fetch data for holdings (limit to first 20 for demo, remove limit for full analysis)\n",
    "print(f\"\\nFetching price data for portfolio holdings...\")\n",
    "ticker_limit = min(20, len(tickers))  # Adjust or remove this limit as needed\n",
    "\n",
    "for i, ticker in enumerate(tickers[:ticker_limit]):\n",
    "    if ticker and ' ' not in ticker and ticker != 'VOO':  # Skip invalid tickers and VOO (already fetched)\n",
    "        print(f\"  [{i+1}/{ticker_limit}] {ticker}...\", end=\" \")\n",
    "        \n",
    "        # Try fund table first for known ETFs\n",
    "        if ticker in COMMON_ETFS:\n",
    "            prices = fetcher.get_fund_prices(ticker, start_date, end_date)\n",
    "            if prices.is_empty():\n",
    "                # Fallback to equity table\n",
    "                prices = fetcher.get_price_history(ticker, start_date, end_date)\n",
    "        else:\n",
    "            # Try equity table first for stocks\n",
    "            prices = fetcher.get_price_history(ticker, start_date, end_date)\n",
    "            if prices.is_empty():\n",
    "                # Fallback to fund table\n",
    "                prices = fetcher.get_fund_prices(ticker, start_date, end_date)\n",
    "        \n",
    "        if not prices.is_empty():\n",
    "            price_data[ticker] = prices\n",
    "            print(f\"✓ ({len(prices)} days)\")\n",
    "        else:\n",
    "            failed_tickers.append(ticker)\n",
    "            print(f\"✗ (no data)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"Successfully fetched data for {len(price_data)} tickers\")\n",
    "if failed_tickers:\n",
    "    print(f\"Failed to fetch data for {len(failed_tickers)} tickers: {', '.join(failed_tickers[:10])}\")\n",
    "    if len(failed_tickers) > 10:\n",
    "        print(f\"  ... and {len(failed_tickers) - 10} more\")\n",
    "\n",
    "# Show sample of fetched data\n",
    "if price_data:\n",
    "    sample_ticker = list(price_data.keys())[0]\n",
    "    print(f\"\\nSample data for {sample_ticker}:\")\n",
    "    print(price_data[sample_ticker].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Portfolio Tracking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create actual portfolio\n",
    "actual_portfolio = Portfolio()\n",
    "\n",
    "# Process all transactions - convert Polars DataFrame to records for iteration\n",
    "for row in equity_transactions.iter_rows(named=True):\n",
    "    actual_portfolio.process_transaction(\n",
    "        date=row['Trade Date'],\n",
    "        txn_type=row['Type'],\n",
    "        ticker=row['Ticker'],\n",
    "        quantity=row.get('Quantity', 0) or 0,\n",
    "        amount=row.get('Amount USD', 0) or 0\n",
    "    )\n",
    "\n",
    "# Calculate final portfolio value\n",
    "final_date = equity_transactions['Trade Date'].max()\n",
    "final_value = actual_portfolio.calculate_value(final_date, price_data)\n",
    "\n",
    "# Calculate XIRR\n",
    "actual_xirr = actual_portfolio.calculate_xirr(final_date, final_value)\n",
    "\n",
    "print(f\"Actual Portfolio Summary:\")\n",
    "print(f\"  Final Value: ${final_value:,.2f}\")\n",
    "print(f\"  Number of transactions: {len(equity_transactions)}\")\n",
    "print(f\"  Number of cash flows: {len(actual_portfolio.cash_flows)}\")\n",
    "if actual_xirr:\n",
    "    print(f\"  XIRR (Annualized Return): {actual_xirr:.2f}%\")\n",
    "else:\n",
    "    print(f\"  XIRR: Could not calculate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Polars join operations\n",
    "print(\"POLARS JOIN OPERATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a summary of holdings\n",
    "holdings_summary = (\n",
    "    equity_transactions\n",
    "    .filter(pl.col('Type').is_in(['BUY', 'SELL']))\n",
    "    .with_columns(\n",
    "        pl.when(pl.col('Type') == 'SELL')\n",
    "        .then(-pl.col('Quantity'))\n",
    "        .otherwise(pl.col('Quantity'))\n",
    "        .alias('adjusted_quantity')\n",
    "    )\n",
    "    .group_by('Ticker')\n",
    "    .agg([\n",
    "        pl.col('adjusted_quantity').sum().alias('net_shares'),\n",
    "        pl.col('Amount USD').filter(pl.col('Type') == 'BUY').sum().abs().alias('total_invested'),\n",
    "        pl.count().alias('transaction_count')\n",
    "    ])\n",
    "    .filter(pl.col('net_shares') > 0)\n",
    ")\n",
    "\n",
    "print(\"\\n1. Current Holdings Summary:\")\n",
    "print(holdings_summary.head(10))\n",
    "\n",
    "# If we have price data, join with current prices\n",
    "if price_data:\n",
    "    # Get latest prices for each ticker\n",
    "    latest_prices = []\n",
    "    for ticker, prices_df in price_data.items():\n",
    "        if not prices_df.is_empty():\n",
    "            latest_price = pl.DataFrame({\n",
    "                'Ticker': [ticker],\n",
    "                'current_price': [prices_df['closeadj'][-1]]\n",
    "            })\n",
    "            latest_prices.append(latest_price)\n",
    "    \n",
    "    if latest_prices:\n",
    "        prices_df = pl.concat(latest_prices)\n",
    "        \n",
    "        # Join holdings with prices\n",
    "        portfolio_values = (\n",
    "            holdings_summary\n",
    "            .join(prices_df, on='Ticker', how='left')\n",
    "            .with_columns(\n",
    "                (pl.col('net_shares') * pl.col('current_price')).alias('current_value')\n",
    "            )\n",
    "            .with_columns(\n",
    "                ((pl.col('current_value') - pl.col('total_invested')) / pl.col('total_invested') * 100)\n",
    "                .alias('return_pct')\n",
    "            )\n",
    "            .sort('current_value', descending=True)\n",
    "        )\n",
    "        \n",
    "        print(\"\\n2. Portfolio Values with Returns:\")\n",
    "        print(portfolio_values.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def simulate_voo_portfolio(transactions_df, voo_prices):\n",
    "    \"\"\"Simulate portfolio if all Buy transactions went to VOO instead\"\"\"\n",
    "    voo_portfolio = Portfolio()\n",
    "    \n",
    "    # Get all buy transactions using Polars\n",
    "    buy_transactions = transactions_df.filter(pl.col('Type') == 'BUY').sort('Trade Date')\n",
    "    \n",
    "    for row in buy_transactions.iter_rows(named=True):\n",
    "        date = row['Trade Date']\n",
    "        amount = abs(row['Amount USD'])\n",
    "        \n",
    "        # Find VOO price on that date using Polars\n",
    "        voo_on_date = voo_prices.filter(pl.col('date') <= date)\n",
    "        if len(voo_on_date) > 0:\n",
    "            voo_price = voo_on_date['closeadj'][-1]\n",
    "            shares = amount / voo_price\n",
    "            \n",
    "            # Simulate buying VOO\n",
    "            voo_portfolio.process_transaction(\n",
    "                date=date,\n",
    "                txn_type='BUY',\n",
    "                ticker='VOO',\n",
    "                quantity=shares,\n",
    "                amount=amount\n",
    "            )\n",
    "    \n",
    "    # Handle dividend reinvestment for VOO\n",
    "    # Get all dividend payments for VOO during holding period\n",
    "    if len(voo_portfolio.holdings) > 0 and 'VOO' in voo_portfolio.holdings:\n",
    "        voo_divs = voo_prices.filter(pl.col('divamt') > 0)\n",
    "        min_date = buy_transactions['Trade Date'].min()\n",
    "        \n",
    "        for row in voo_divs.iter_rows(named=True):\n",
    "            div_date = row['date']\n",
    "            # Only process if we held shares on this date\n",
    "            if div_date >= min_date:\n",
    "                shares_held = voo_portfolio.holdings.get('VOO', 0)\n",
    "                if shares_held > 0:\n",
    "                    div_amount = shares_held * row['divamt']\n",
    "                    new_shares = div_amount / row['closeadj']\n",
    "                    # Reinvest dividend\n",
    "                    voo_portfolio.process_transaction(\n",
    "                        date=div_date,\n",
    "                        txn_type='REINVEST',\n",
    "                        ticker='VOO',\n",
    "                        quantity=new_shares,\n",
    "                        amount=div_amount\n",
    "                    )\n",
    "    \n",
    "    return voo_portfolio\n",
    "\n",
    "# Simulate VOO portfolio\n",
    "if 'VOO' in price_data:\n",
    "    voo_portfolio = simulate_voo_portfolio(equity_transactions, price_data['VOO'])\n",
    "    voo_final_value = voo_portfolio.calculate_value(final_date, price_data)\n",
    "    voo_xirr = voo_portfolio.calculate_xirr(final_date, voo_final_value)\n",
    "    \n",
    "    print(f\"VOO Benchmark Portfolio:\")\n",
    "    print(f\"  Final Value: ${voo_final_value:,.2f}\")\n",
    "    print(f\"  Total VOO shares: {voo_portfolio.holdings.get('VOO', 0):.4f}\")\n",
    "    if voo_xirr:\n",
    "        print(f\"  XIRR (Annualized Return): {voo_xirr:.2f}%\")\n",
    "else:\n",
    "    print(\"VOO price data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fetch Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_portfolios(actual_xirr, voo_xirr, actual_value, voo_value, transactions_df):\n",
    "    \"\"\"Compare actual vs VOO benchmark returns using Polars DataFrame\"\"\"\n",
    "    \n",
    "    # Calculate total invested using Polars\n",
    "    total_invested = abs(\n",
    "        transactions_df\n",
    "        .filter(pl.col('Type') == 'BUY')\n",
    "        .select(pl.col('Amount USD').sum())\n",
    "        .item()\n",
    "    )\n",
    "    \n",
    "    # Calculate time period using Polars\n",
    "    date_range = transactions_df.select([\n",
    "        pl.col('Trade Date').min().alias('start_date'),\n",
    "        pl.col('Trade Date').max().alias('end_date')\n",
    "    ]).row(0)\n",
    "    \n",
    "    start_date = date_range[0]\n",
    "    end_date = date_range[1]\n",
    "    years = (end_date - start_date).days / 365.25\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"PORTFOLIO COMPARISON RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nInvestment Period: {start_date} to {end_date} ({years:.1f} years)\")\n",
    "    print(f\"Total Invested: ${total_invested:,.2f}\")\n",
    "    \n",
    "    print(f\"\\nActual Portfolio:\")\n",
    "    print(f\"  Final Value: ${actual_value:,.2f}\")\n",
    "    print(f\"  Total Return: {((actual_value/total_invested - 1) * 100):.2f}%\")\n",
    "    if actual_xirr:\n",
    "        print(f\"  XIRR (Annualized): {actual_xirr:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nVOO Benchmark:\")\n",
    "    print(f\"  Final Value: ${voo_value:,.2f}\")\n",
    "    print(f\"  Total Return: {((voo_value/total_invested - 1) * 100):.2f}%\")\n",
    "    if voo_xirr:\n",
    "        print(f\"  XIRR (Annualized): {voo_xirr:.2f}%\")\n",
    "    \n",
    "    if actual_xirr and voo_xirr:\n",
    "        print(f\"\\nPerformance Analysis:\")\n",
    "        outperformance = actual_xirr - voo_xirr\n",
    "        if outperformance > 0:\n",
    "            print(f\"  ✅ Your portfolio OUTPERFORMED VOO by {outperformance:.2f}% annually\")\n",
    "        else:\n",
    "            print(f\"  ❌ Your portfolio UNDERPERFORMED VOO by {abs(outperformance):.2f}% annually\")\n",
    "        \n",
    "        # Calculate dollar difference\n",
    "        dollar_diff = actual_value - voo_value\n",
    "        if dollar_diff > 0:\n",
    "            print(f\"  💰 You have ${dollar_diff:,.2f} more than the VOO strategy\")\n",
    "        else:\n",
    "            print(f\"  💸 You have ${abs(dollar_diff):,.2f} less than the VOO strategy\")\n",
    "\n",
    "# Run comparison\n",
    "if 'voo_xirr' in locals():\n",
    "    compare_portfolios(actual_xirr, voo_xirr, final_value, voo_final_value, equity_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Calculate Actual Portfolio Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio composition analysis using Polars\n",
    "holdings_summary = (\n",
    "    equity_transactions\n",
    "    .group_by('Ticker')\n",
    "    .agg(pl.col('Amount USD').sum().abs().alias('total_amount'))\n",
    "    .sort('total_amount', descending=True)\n",
    ")\n",
    "top_holdings = holdings_summary.head(10)\n",
    "\n",
    "# Convert to pandas for matplotlib (visualization still needs pandas)\n",
    "top_holdings_pd = top_holdings.to_pandas()\n",
    "equity_transactions_pd = equity_transactions.to_pandas()\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Top holdings by investment amount\n",
    "ax1 = axes[0, 0]\n",
    "ax1.barh(top_holdings_pd['Ticker'], top_holdings_pd['total_amount'], color='steelblue')\n",
    "ax1.set_title('Top 10 Holdings by Total Investment', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Total Invested ($)')\n",
    "ax1.set_ylabel('Ticker')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# 2. Transaction types distribution\n",
    "ax2 = axes[0, 1]\n",
    "txn_types = equity_transactions['Type'].value_counts().to_pandas()\n",
    "colors = plt.cm.Set3(range(len(txn_types)))\n",
    "txn_types.plot(kind='pie', ax=ax2, autopct='%1.1f%%', colors=colors)\n",
    "ax2.set_title('Transaction Types Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "# 3. Investment timeline\n",
    "ax3 = axes[1, 0]\n",
    "monthly_buys = (\n",
    "    equity_transactions\n",
    "    .filter(pl.col('Type') == 'BUY')\n",
    "    .with_columns(\n",
    "        pl.col('Trade Date').dt.to_string('%Y-%m').alias('YearMonth')\n",
    "    )\n",
    "    .group_by('YearMonth')\n",
    "    .agg(pl.col('Amount USD').sum().abs().alias('monthly_amount'))\n",
    "    .sort('YearMonth')\n",
    "    .to_pandas()\n",
    ")\n",
    "ax3.bar(range(len(monthly_buys)), monthly_buys['monthly_amount'], color='green', alpha=0.7)\n",
    "ax3.set_title('Monthly Investment Pattern', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Month')\n",
    "ax3.set_ylabel('Amount Invested ($)')\n",
    "ax3.set_xticks(range(0, len(monthly_buys), max(1, len(monthly_buys)//10)))\n",
    "ax3.set_xticklabels(monthly_buys['YearMonth'].iloc[::max(1, len(monthly_buys)//10)], rotation=45)\n",
    "\n",
    "# 4. Cumulative investment over time\n",
    "ax4 = axes[1, 1]\n",
    "buys_only = (\n",
    "    equity_transactions\n",
    "    .filter(pl.col('Type') == 'BUY')\n",
    "    .sort('Trade Date')\n",
    "    .with_columns(\n",
    "        pl.col('Amount USD').abs().cum_sum().alias('Cumulative')\n",
    "    )\n",
    "    .to_pandas()\n",
    ")\n",
    "ax4.plot(buys_only['Trade Date'], buys_only['Cumulative'], linewidth=2, color='navy')\n",
    "ax4.fill_between(buys_only['Trade Date'], 0, buys_only['Cumulative'], alpha=0.3, color='navy')\n",
    "ax4.set_title('Cumulative Investment Over Time', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.set_ylabel('Cumulative Investment ($)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Simulate VOO Benchmark Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze returns by year using Polars\n",
    "def analyze_by_year(transactions_df):\n",
    "    \"\"\"Break down investment activity by year using Polars\"\"\"\n",
    "    \n",
    "    yearly_analysis = (\n",
    "        transactions_df\n",
    "        .with_columns(\n",
    "            pl.col('Trade Date').dt.year().alias('Year')\n",
    "        )\n",
    "        .group_by('Year')\n",
    "        .agg([\n",
    "            # Calculate invested amount (BUY transactions)\n",
    "            pl.col('Amount USD')\n",
    "                .filter(pl.col('Type') == 'BUY')\n",
    "                .sum().abs()\n",
    "                .alias('Invested'),\n",
    "            \n",
    "            # Calculate sold amount (SELL transactions)\n",
    "            pl.col('Amount USD')\n",
    "                .filter(pl.col('Type') == 'SELL')\n",
    "                .sum().abs()\n",
    "                .alias('Sold'),\n",
    "            \n",
    "            # Calculate dividends\n",
    "            pl.col('Amount USD')\n",
    "                .filter(pl.col('Type').is_in(['DIVIDEND', 'REINVEST']))\n",
    "                .sum().abs()\n",
    "                .alias('Dividends'),\n",
    "            \n",
    "            # Count transactions\n",
    "            pl.count().alias('Transactions')\n",
    "        ])\n",
    "        .with_columns(\n",
    "            (-pl.col('Invested') + pl.col('Sold')).alias('Net Cash Flow')\n",
    "        )\n",
    "        .sort('Year')\n",
    "    )\n",
    "    \n",
    "    return yearly_analysis\n",
    "\n",
    "yearly_analysis = analyze_by_year(equity_transactions)\n",
    "print(\"Investment Activity by Year (Polars Analysis):\")\n",
    "print(yearly_analysis)\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "yearly_pandas = yearly_analysis.to_pandas()\n",
    "\n",
    "# Visualize yearly activity\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = yearly_pandas['Year']\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, yearly_pandas['Invested'], width, label='Invested', color='green', alpha=0.7)\n",
    "ax.bar(x + width/2, yearly_pandas['Sold'], width, label='Sold', color='red', alpha=0.7)\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Amount ($)', fontsize=12)\n",
    "ax.set_title('Annual Investment and Sales Activity', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary: Key Polars Features Demonstrated\n",
    "\n",
    "This notebook showcased Polars for investment portfolio analysis with these key features:\n",
    "\n",
    "### 1. **Performance Benefits**\n",
    "- Lazy evaluation for query optimization\n",
    "- Parallel execution of operations\n",
    "- Memory-efficient columnar storage\n",
    "- Streaming support for large datasets\n",
    "\n",
    "### 2. **Expression API**\n",
    "- Chainable operations: `filter()`, `with_columns()`, `group_by()`, `agg()`\n",
    "- Window functions with `over()`\n",
    "- Conditional logic with `when().then().otherwise()`\n",
    "- Date/time operations with `.dt` namespace\n",
    "\n",
    "### 3. **Data Operations**\n",
    "- **Selection**: `select()`, column subsetting\n",
    "- **Filtering**: `filter()` with boolean expressions\n",
    "- **Aggregation**: `group_by()` with multiple aggregation functions\n",
    "- **Joins**: `join()` for combining DataFrames\n",
    "- **Pivoting**: `pivot()` for reshaping data\n",
    "- **Sorting**: `sort()` with multiple columns\n",
    "\n",
    "### 4. **Polars vs Pandas Comparison**\n",
    "| Feature | Polars | Pandas |\n",
    "|---------|--------|--------|\n",
    "| Speed | 5-10x faster for large datasets | Baseline |\n",
    "| Memory | More efficient, columnar storage | Row-based |\n",
    "| API | Consistent, predictable | More flexible but inconsistent |\n",
    "| Lazy Evaluation | Yes, with query optimization | No |\n",
    "| Type Safety | Strong typing | Weaker typing |\n",
    "| Null Handling | Explicit null type | NaN/None mixing |\n",
    "\n",
    "### 5. **Common Polars Patterns Used**\n",
    "```python\n",
    "# Chain operations\n",
    "df.filter(...).with_columns(...).group_by(...).agg(...)\n",
    "\n",
    "# Lazy evaluation\n",
    "df.lazy().filter(...).collect()\n",
    "\n",
    "# Window functions\n",
    "pl.col(\"amount\").cum_sum().over(\"ticker\")\n",
    "\n",
    "# Conditional columns\n",
    "pl.when(condition).then(value1).otherwise(value2)\n",
    "\n",
    "# Date operations\n",
    "pl.col(\"date\").dt.year()\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "- Use `streaming=True` in `collect()` for very large datasets\n",
    "- Explore Polars plugins for specialized operations\n",
    "- Consider Polars for ETL pipelines and data processing workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars Lazy Evaluation and Query Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_portfolios(actual_xirr, voo_xirr, actual_value, voo_value, transactions_df):\n",
    "    \"\"\"Compare actual vs VOO benchmark returns\"\"\"\n",
    "    \n",
    "    # Calculate total invested\n",
    "    total_invested = abs(transactions_df[transactions_df['Type'] == 'Buy']['Amount USD'].sum())\n",
    "    \n",
    "    # Calculate time period\n",
    "    start_date = transactions_df['Trade Date'].min()\n",
    "    end_date = transactions_df['Trade Date'].max()\n",
    "    years = (end_date - start_date).days / 365.25\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"PORTFOLIO COMPARISON RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nInvestment Period: {start_date.date()} to {end_date.date()} ({years:.1f} years)\")\n",
    "    print(f\"Total Invested: ${total_invested:,.2f}\")\n",
    "    \n",
    "    print(f\"\\nActual Portfolio:\")\n",
    "    print(f\"  Final Value: ${actual_value:,.2f}\")\n",
    "    print(f\"  Total Return: {((actual_value/total_invested - 1) * 100):.2f}%\")\n",
    "    if actual_xirr:\n",
    "        print(f\"  XIRR (Annualized): {actual_xirr:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nVOO Benchmark:\")\n",
    "    print(f\"  Final Value: ${voo_value:,.2f}\")\n",
    "    print(f\"  Total Return: {((voo_value/total_invested - 1) * 100):.2f}%\")\n",
    "    if voo_xirr:\n",
    "        print(f\"  XIRR (Annualized): {voo_xirr:.2f}%\")\n",
    "    \n",
    "    if actual_xirr and voo_xirr:\n",
    "        print(f\"\\nPerformance Analysis:\")\n",
    "        outperformance = actual_xirr - voo_xirr\n",
    "        if outperformance > 0:\n",
    "            print(f\"  ✅ Your portfolio OUTPERFORMED VOO by {outperformance:.2f}% annually\")\n",
    "        else:\n",
    "            print(f\"  ❌ Your portfolio UNDERPERFORMED VOO by {abs(outperformance):.2f}% annually\")\n",
    "        \n",
    "        # Calculate dollar difference\n",
    "        dollar_diff = actual_value - voo_value\n",
    "        if dollar_diff > 0:\n",
    "            print(f\"  💰 You have ${dollar_diff:,.2f} more than the VOO strategy\")\n",
    "        else:\n",
    "            print(f\"  💸 You have ${abs(dollar_diff):,.2f} less than the VOO strategy\")\n",
    "\n",
    "# Run comparison\n",
    "if 'voo_xirr' in locals():\n",
    "    compare_portfolios(actual_xirr, voo_xirr, final_value, voo_final_value, equity_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio composition analysis\n",
    "holdings_summary = equity_transactions.groupby('Ticker')['Amount USD'].sum().abs().sort_values(ascending=False)\n",
    "top_holdings = holdings_summary.head(10)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Top holdings by investment amount\n",
    "ax1 = axes[0, 0]\n",
    "top_holdings.plot(kind='barh', ax=ax1, color='steelblue')\n",
    "ax1.set_title('Top 10 Holdings by Total Investment', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Total Invested ($)')\n",
    "ax1.set_ylabel('Ticker')\n",
    "\n",
    "# 2. Transaction types distribution\n",
    "ax2 = axes[0, 1]\n",
    "txn_types = equity_transactions['Type'].value_counts()\n",
    "colors = plt.cm.Set3(range(len(txn_types)))\n",
    "txn_types.plot(kind='pie', ax=ax2, autopct='%1.1f%%', colors=colors)\n",
    "ax2.set_title('Transaction Types Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "# 3. Investment timeline\n",
    "ax3 = axes[1, 0]\n",
    "monthly_buys = equity_transactions[equity_transactions['Type'] == 'Buy'].copy()\n",
    "monthly_buys['YearMonth'] = monthly_buys['Trade Date'].dt.to_period('M')\n",
    "monthly_investment = monthly_buys.groupby('YearMonth')['Amount USD'].sum().abs()\n",
    "monthly_investment.plot(kind='bar', ax=ax3, color='green', alpha=0.7)\n",
    "ax3.set_title('Monthly Investment Pattern', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Month')\n",
    "ax3.set_ylabel('Amount Invested ($)')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Cumulative investment over time\n",
    "ax4 = axes[1, 1]\n",
    "buys_only = equity_transactions[equity_transactions['Type'] == 'Buy'].copy()\n",
    "buys_only = buys_only.sort_values('Trade Date')\n",
    "buys_only['Cumulative'] = buys_only['Amount USD'].abs().cumsum()\n",
    "ax4.plot(buys_only['Trade Date'], buys_only['Cumulative'], linewidth=2, color='navy')\n",
    "ax4.fill_between(buys_only['Trade Date'], 0, buys_only['Cumulative'], alpha=0.3, color='navy')\n",
    "ax4.set_title('Cumulative Investment Over Time', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.set_ylabel('Cumulative Investment ($)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Detailed Analysis by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze returns by year\n",
    "def analyze_by_year(transactions_df):\n",
    "    \"\"\"Break down investment activity by year\"\"\"\n",
    "    df = transactions_df.copy()\n",
    "    df['Year'] = df['Trade Date'].dt.year\n",
    "    \n",
    "    yearly_summary = []\n",
    "    for year in sorted(df['Year'].unique()):\n",
    "        year_data = df[df['Year'] == year]\n",
    "        buys = year_data[year_data['Type'] == 'Buy']['Amount USD'].sum()\n",
    "        sells = year_data[year_data['Type'] == 'Sell']['Amount USD'].sum()\n",
    "        dividends = year_data[year_data['Type'].isin(['Dividend', 'Reinvest'])]['Amount USD'].sum()\n",
    "        \n",
    "        yearly_summary.append({\n",
    "            'Year': year,\n",
    "            'Invested': abs(buys),\n",
    "            'Sold': abs(sells),\n",
    "            'Dividends': abs(dividends),\n",
    "            'Net Cash Flow': -abs(buys) + abs(sells),\n",
    "            'Transactions': len(year_data)\n",
    "        })\n",
    "    \n",
    "    yearly_df = pd.DataFrame(yearly_summary)\n",
    "    return yearly_df\n",
    "\n",
    "yearly_analysis = analyze_by_year(equity_transactions)\n",
    "print(\"Investment Activity by Year:\")\n",
    "print(yearly_analysis.to_string(index=False))\n",
    "\n",
    "# Visualize yearly activity\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = yearly_analysis['Year']\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, yearly_analysis['Invested'], width, label='Invested', color='green', alpha=0.7)\n",
    "ax.bar(x + width/2, yearly_analysis['Sold'], width, label='Sold', color='red', alpha=0.7)\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Amount ($)', fontsize=12)\n",
    "ax.set_title('Annual Investment and Sales Activity', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Next Steps\n",
    "\n",
    "This notebook provides a comprehensive analysis of your investment portfolio performance using XIRR (money-weighted returns) compared to a VOO benchmark strategy.\n",
    "\n",
    "### Key Insights:\n",
    "1. **XIRR vs CAGR**: We use XIRR because it accounts for the timing and size of your cash flows, giving a more accurate picture of your investment performance\n",
    "2. **Dividend Reinvestment**: Properly handled by tracking share increases without affecting XIRR cash flows\n",
    "3. **Fair Comparison**: The VOO benchmark simulates investing the same amounts on the same dates as your actual investments\n",
    "\n",
    "### To Run This Analysis:\n",
    "1. Set your Nasdaq Data Link API key: `export NASDAQ_DATA_LINK_API_KEY=\"your_key\"`\n",
    "2. Run each cell sequentially to see results\n",
    "3. The analysis will work with dummy data if no API key is provided (for testing)\n",
    "\n",
    "### Potential Enhancements:\n",
    "- Add support for stock splits and corporate actions\n",
    "- Include transaction costs in the analysis\n",
    "- Compare against multiple benchmarks (QQQ, IWM, etc.)\n",
    "- Add risk-adjusted return metrics (Sharpe ratio, etc.)\n",
    "- Generate a detailed PDF report of findings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antichain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
